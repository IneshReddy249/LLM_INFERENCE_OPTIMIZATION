{
  "engine": "tensorrt_throughput",
  "mode": "batch_processing",
  "batch_size": 4,
  "prompts": [
    "Explain paged KV cache.",
    "What does remove_input_padding do in TensorRT-LLM?",
    "Give 3 ways to improve LLM throughput on A100.",
    "Difference between paged KV cache and normal KV cache?"
  ],
  "total_prompt_tokens": 46,
  "total_generated_tokens": 512,
  "ttft_ms": 13.213396072387695,
  "latency_avg_s": 1.3845591497421266,
  "latency_p50_s": 1.3839573860168457,
  "latency_p95_s": 1.3900431871414185,
  "latency_p99_s": 1.3951807260513305,
  "total_tokens_per_sec": 373.3558795292007,
  "memory_used_gb": 0.029386239999999998,
  "memory_peak_gb": 0.046508032,
  "gpu_util_pct": 95.0
}